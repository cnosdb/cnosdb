[global]
# node_id = 100
host = "localhost"
cluster_name = 'cluster_xxx'
store_metrics = true
pre_create_bucket = false

[deployment]
# mode = 'query_tskv'
# cpu = 8
# memory = 16

[meta]
service_addr = ["127.0.0.1:8901"]
report_time_interval = "30s"
usage_schema_cache_size = "2MiB"
cluster_schema_cache_size = "2MiB"

[query]
max_server_connections = 10240
query_sql_limit = "16M"  # 16,777,216 bytes
write_sql_limit = "160M" # 167,772,160 bytes
auth_enabled = false
read_timeout = "3000ms"
write_timeout = "3000ms"
stream_trigger_cpu = 1
stream_executor_cpu = 2
sql_record_timeout = "10s"

[storage]

## The directory where database files stored.
# Directory for summary:    $path/summary
# Directory for index:      $path/$database/data/id/index
# Directory for tsm:        $path/$database/data/id/tsm
# Directory for delta:      $path/$database/data/id/delta
path = '/var/lib/cnosdb/data'

## The maximum file size of summary file.
# max_summary_size = "128M" # 134,217,728 bytes

## The maximum file size of a level is as follows:
## $base_file_size * level * $compact_trigger_file_num
# base_file_size = "16M" # 16,777,216 bytes

## The maximum amount of flush requests in memory
# flush_req_channel_cap = 16

## The maximum count of opened file handles (for query) in each vnode.
# max_cached_readers = 32

## The maximum level of a data file (from 0 to 4).
# max_level = 4

# Trigger of compaction using the number of level 0 files.
# compact_trigger_file_num = 4

## Duration since last write to trigger compaction.
# compact_trigger_cold_duration = "1h"

## The maximum size of all files in a compaction.
# max_compact_size = "2G" # 2,147,483,648 bytes

## The maximum concurrent compactions.
# max_concurrent_compaction = 4

## If true, write request will not be checked in detail.
strict_write = false

## copyinto trigger flush size
#copyinto_trigger_flush_size = "128M" # 134217728

## The maximum size of a datablock in compaction. 
max_datablock_size = "100KiB"

## index cache capacity in every vnode
index_cache_capacity = 100000

## reserve space for data stroage
reserve_space = '0G'
## the parallel of read file
read_parallel = 8

[wal]

## The directory where write ahead logs stored.
path = '/var/lib/cnosdb/wal'

## The maximum amount of write request in memory.
# wal_req_channel_cap = 64

## The maximum size of a WAL.
# max_file_size = '1G' # 1,073,741,824 bytes

## If true, fsync will be called after every WAL writes.
# sync = false

## wal compress type
# compress = "zstd"

[cache]

## The maximum size of a mutable cache.
# max_buffer_size = '128M' # 134,217,728 bytes

## The partition number of memcache cache,default equal to cpu number
# partition = 8

[log]
level = 'info'
path = '/var/log/cnosdb'

## Keeps the last [max_file_count] log files on disk. When a new log file
## is created, if there are [max_file_count] or more existing log files in
## the directory, the oldest will be deleted. If no value is supplied, the
## old file will not be removed.
# max_file_count = 10

## Defines a fixed period for rolling of a log file, Optional values ​​are
## "daily", "hourly", "minutely", "never"
# file_rotation = "daily"

## Tokio trace, default turn off tokio trace
# tokio_trace = { addr = "127.0.0.1:6669" }

[security]
# [security.tls_config]
# certificate = "/etc/config/tls/server.crt"
# private_key = "/etc/config/tls/server.key"

[service]
http_listen_port = 8902
grpc_listen_port = 8903
grpc_enable_gzip = false
flight_rpc_listen_port = 8904
tcp_listen_port = 8905
vector_listen_port = 8906
enable_report = true

[cluster]
# raft_logs_to_keep = 5000

# [trace]
# auto_generate_span = false
# otlp_endpoint = 'http://localhost:4317'
# max_spans_per_trace = 100
# batch_report_interval = "500ms"
# batch_report_max_spans = 100
